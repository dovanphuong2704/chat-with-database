{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935e08ea-ad7f-4da4-a8ec-2b98d3e218b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import mercury as mr\n",
    "import ollama\n",
    "from typing import Optional\n",
    "from dbclient import DatabaseClient\n",
    "from safeish import SafeishPythonExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525cb845-7f51-4949-a53e-c4a2054e4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DatabaseClient()\n",
    "db_schema = db.get_schema_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475848f6-89b7-4366-8ef4-ab08c22582a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are an SQL assistant connected directly to a PostgreSQL database. \"\n",
    "        \"You can execute SELECT queries on this database, \"\n",
    "        \"and your system will automatically run any SQL query you provide. \"\n",
    "        \"Always try to answer user questions by generating and executing an SQL query first, \"\n",
    "        \"even if you think you already know the answer logically. \"\n",
    "        \"Never assume the result â€” always verify it in the database. \"\n",
    "        \"Only if the question cannot possibly be answered with SQL, then ask for clarification. \"\n",
    "        \"Use SELECT statements only (no INSERT, UPDATE, DELETE). \"\n",
    "        \"When creating visualizations (such as charts, graphs, or plots), \"\n",
    "        \"Use the Altair library for all visual outputs. It is already available\\n\"\n",
    "        \"Create chart object with Altair. I will do display(chart). Please set width to 600px. \"\n",
    "        \"Data is in pandas dataframe called df - use df variable. DONT create sample df variable. \"\n",
    "        \"If you think you need another library, do not attempt to import it â€” \"\n",
    "        \"simply explain that it is not available. \"\n",
    "        \"Database schema:\\n\"\n",
    "        f\"{db_schema}\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a898162-9164-439a-8707-8dafadeedb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(sql: str) -> pd.DataFrame:\n",
    "    \"\"\"Query database \n",
    "    \n",
    "    Args:\n",
    "      sql: SQL query to be executed\n",
    "    \n",
    "    Returns:\n",
    "      Pandas DataFrame with query results\n",
    "    \"\"\"\n",
    "    result = db.query(sql)\n",
    "    df = DatabaseClient.to_dataframe(result)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20b3bd1-546b-4d25-b6f4-969ed2fd8842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_atair_chart(python_code) -> Optional[alt.Chart]:\n",
    "    \"\"\"Execute python code to create Altair plot on last query result\n",
    "    \n",
    "    Args:\n",
    "      python_code: string with python code that will create altair chart\n",
    "\n",
    "    Returns:\n",
    "      Altair chart object\n",
    "    \"\"\"\n",
    "        \n",
    "    executor = SafeishPythonExecutor(safe_globals={\"alt\": alt, \"pd\": pd})\n",
    "\n",
    "    res = executor.run(\n",
    "        python_code,\n",
    "        context={\"df\": df},   # last query result\n",
    "        return_locals=True,\n",
    "    )\n",
    "\n",
    "    chart = None\n",
    "    if res.ok:\n",
    "        chart = res.locals.get(\"chart\")\n",
    "    else:\n",
    "        print(res.error)\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38ab924-0356-4b51-aed6-25b46eb0c727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae11457eba7440f8b3d164b9606e65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <div style=\"\\n              color:#b5b5b5;\\n              text-align:â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5f9ec5d6ce40e983bbd766743a4989",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<mercury.chat.chat.ScrollHelper object at 0x7de9a8bc2250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = mr.Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74045c3c-058a-4dcc-8fba-74ab41698380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": {
       "model_id": "8b13de9fac62450e803abc1dfb5248c5",
       "position": "bottom",
       "widget": "ChatInputWidget"
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b13de9fac62450e803abc1dfb5248c5",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<mercury.chat.chatinput.ChatInputWidget object at 0x7de9a8ba3790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = mr.ChatInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b1f7ee-81d6-4ee8-9437-c5bf5a4f4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prompt.value:\n",
    "\n",
    "    user_msg = mr.Message(prompt.value, role=\"user\", emoji=\"ðŸ‘¤\")\n",
    "    chat.add(user_msg)\n",
    "\n",
    "    ai_msg = mr.Message(role=\"assistant\", emoji=\"ðŸ¤–\")\n",
    "    ai_msg.set_gradient_text(\"Thinking ...\")\n",
    "    chat.add(ai_msg)\n",
    "    \n",
    "    messages += [{\"role\": \"user\", \"content\": prompt.value}]\n",
    "    response = ollama.chat(\n",
    "      model='gpt-oss:20b',\n",
    "      messages=messages,\n",
    "      think='low',\n",
    "      tools=[query_database, create_atair_chart]\n",
    "    )\n",
    "    messages.append(response.message.model_dump(exclude_none=True))\n",
    "    if response.message.thinking:\n",
    "        ai_msg.append_markdown(response.message.thinking)\n",
    "    if response.message.content:\n",
    "        ai_msg.append_markdown(response.message.content)\n",
    "        \n",
    "    if response.message.tool_calls:\n",
    "        for tc in response.message.tool_calls:\n",
    "    \n",
    "            if tc.function.name == \"query_database\":\n",
    "                \n",
    "                with ai_msg:\n",
    "                    sql_expander = mr.Expander(\"âš’ï¸ SQL query\", key=f\"expander-{len(messages)}\")\n",
    "                    with sql_expander:\n",
    "                        print(tc.function.arguments[\"sql\"])\n",
    "                    \n",
    "                df = query_database(**tc.function.arguments)\n",
    "                messages.append({'role': 'tool', 'tool_name': tc.function.name, 'content': DatabaseClient.describe_dataframe_for_llm(df)})\n",
    "                with ai_msg:\n",
    "                    display(df)\n",
    "                    \n",
    "            elif tc.function.name == \"create_atair_chart\":\n",
    "                chart = create_atair_chart(tc.function.arguments[\"python_code\"])\n",
    "                messages.append({'role': 'tool', 'tool_name': tc.function.name, 'content': \"Plot created\" if chart else \"Cant create a plot\"})\n",
    "                if chart:\n",
    "                    with ai_msg:\n",
    "                        display(chart)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bab070-df6f-4a87-8f54-5ca78fe7e47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "mercury": {
   "description": "Text-to-SQL",
   "thumbnail_bg": "#71aefe",
   "thumbnail_text": "ðŸ“Š",
   "title": "SQL assistant"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bc80ea642a548a7b256cad423509fdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5a5f9ec5d6ce40e983bbd766743a4989": {
      "model_module": "anywidget",
      "model_module_version": "~0.9.*",
      "model_name": "AnyModel",
      "state": {
       "_anywidget_id": "mercury.chat.chat.ScrollHelper",
       "_css": "\n    .mljar-chat-scroll-helper {\n        display: none;\n    }\n    ",
       "_esm": "\nfunction render({ model, el }) {\n  const LOG_PREFIX = \"[ScrollHelper]\";\n  const MSG_CLASS = model.get(\"msg_css_class\") || \"mljar-chat-msg\";\n\n  // Just in case, hide the helper element itself\n  el.classList.add(\"mljar-chat-scroll-helper\");\n\n  function isScrollable(elem) {\n    if (!elem) return false;\n    const cs = getComputedStyle(elem);\n    const oy = cs.overflowY;\n    const o = cs.overflow;\n    const canScroll = elem.scrollHeight > (elem.clientHeight + 2);\n    return (\n      canScroll &&\n      (oy === \"auto\" || oy === \"scroll\" || o === \"auto\" || o === \"scroll\")\n    );\n  }\n\n  function findScrollableWithin(rootEl) {\n    if (!rootEl) return null;\n    if (isScrollable(rootEl)) return rootEl;\n\n    const walker = document.createTreeWalker(\n      rootEl,\n      NodeFilter.SHOW_ELEMENT,\n      null\n    );\n    let n = walker.currentNode;\n    while ((n = walker.nextNode())) {\n      if (isScrollable(n)) return n;\n    }\n    return null;\n  }\n\n  function getScrollableAncestor(node) {\n    let cur = node && node.parentElement;\n    while (cur) {\n      if (isScrollable(cur)) return cur;\n      cur = cur.parentElement;\n    }\n    return null;\n  }\n\n  function scrollIntoContainer(elem, container) {\n    if (!elem || !container) return;\n    let y = 0;\n    let n = elem;\n    while (n && n !== container) {\n      y += n.offsetTop || 0;\n      n = n.offsetParent;\n    }\n    const target = Math.max(\n      0,\n      y - (container.clientHeight - elem.clientHeight) + 16\n    );\n    container.scrollTop = target;\n  }\n\n  function scrollPageFallback(elem) {\n    try {\n      elem.scrollIntoView({ behavior: \"smooth\", block: \"end\" });\n    } catch (e) {\n      // ignore\n    }\n  }\n\n  function autoScroll() {\n    const msgs = document.getElementsByClassName(MSG_CLASS);\n    if (!msgs || !msgs.length) return;\n    const last = msgs[msgs.length - 1];\n\n    const selector =\n      model.get(\"scroll_container_selector\") ||\n      \"#mercury-main-panel, .mercury-main-panel\";\n\n    let pref = null;\n    try {\n      pref = document.querySelector(selector);\n    } catch (e) {\n      console.warn(LOG_PREFIX, \"bad selector\", selector, e);\n    }\n\n    const scroller =\n      findScrollableWithin(pref) ||\n      getScrollableAncestor(last) ||\n      document.scrollingElement ||\n      document.documentElement;\n\n    if (scroller) {\n      scrollIntoContainer(last, scroller);\n    } else {\n      scrollPageFallback(last);\n    }\n  }\n\n  function scheduleScroll() {\n    // Give big outputs (plots, images) a moment to layout\n    requestAnimationFrame(() => {\n      setTimeout(autoScroll, 100);\n    });\n  }\n\n  // initial scroll attempt (in case messages already present)\n  scheduleScroll();\n\n  // each time Python bumps `tick`, schedule scroll\n  model.on(\"change:tick\", scheduleScroll);\n}\nexport default { render };\n    ",
       "_model_module": "anywidget",
       "_model_module_version": "~0.9.*",
       "_model_name": "AnyModel",
       "_view_module": "anywidget",
       "_view_module_version": "~0.9.*",
       "_view_name": "AnyView",
       "layout": "IPY_MODEL_0bc80ea642a548a7b256cad423509fdc",
       "msg_css_class": "mljar-chat-msg",
       "scroll_container_selector": "#mercury-main-panel, .mercury-main-panel",
       "tick": 0
      }
     },
     "5ae11457eba7440f8b3d164b9606e65b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bbceddcd455b41119043b55979a1d985"
       ],
       "layout": "IPY_MODEL_e9320de6d5ed435e85967fea8aed6f8e"
      }
     },
     "8181adf609a04853a9a2a5fb5ba3588d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8b13de9fac62450e803abc1dfb5248c5": {
      "model_module": "anywidget",
      "model_module_version": "~0.9.*",
      "model_name": "AnyModel",
      "state": {
       "_anywidget_id": "mercury.chat.chatinput.ChatInputWidget",
       "_css": "\n    .mljar-chatinput-container {\n        display: flex;\n        flex-direction: row;\n        align-items: center;\n        width: 100%;\n        min-width: 160px;\n        box-sizing: border-box;\n        gap: 8px;\n        font-family: Arial, sans-serif;\n        font-size: 14px;\n        color: #222;\n        padding-top: 8px;\n        padding-bottom: 8px;\n    }\n\n    .mljar-chatinput-input {\n        flex: 1 1 auto;\n        width: 100%;\n        border: 1px solid #ccc;\n        border-radius: 6px;\n        padding: 6px 10px;\n        min-height: 1.6em;\n        background: #fff;\n        color: #222;\n        box-sizing: border-box;\n        padding: 10px;\n        font-size: 0.9rem;\n    }\n\n    .mljar-chatinput-input:focus {\n        outline: none;\n        border-color: #007bff;\n    }\n\n    .mljar-chatinput-button {\n        flex: 0 0 auto;\n        border: none;\n        border-radius: 6px !important;\n        min-height: 1.6em;\n        cursor: pointer;\n        background: #007bff;\n        color: #fff;\n        font-weight: bold;\n        padding: 11px;\n        padding-left: 18px;\n        padding-right: 18px;\n    }\n\n    .mljar-chatinput-button:hover {\n        filter: brightness(0.95);\n    }\n    ",
       "_esm": "\n    function render({ model, el }) {\n      el.style.flex = \"0 0 auto\";\n      const container = document.createElement(\"div\");\n      container.classList.add(\"mljar-chatinput-container\");\n\n      const input = document.createElement(\"input\");\n      input.type = \"text\";\n      input.placeholder = model.get(\"placeholder\") || \"Type a message...\";\n      input.value = model.get(\"value\") || \"\";\n      input.classList.add(\"mljar-chatinput-input\");\n\n      const btn = document.createElement(\"button\");\n      btn.type = \"button\";\n      btn.classList.add(\"mljar-chatinput-button\");\n      btn.textContent = model.get(\"button_icon\") || \" âž¤ \";\n      btn.setAttribute(\"aria-label\", \"Send message\");\n\n      container.appendChild(input);\n      container.appendChild(btn);\n      el.appendChild(container);\n\n      let lastModelValue = model.get(\"value\") ?? \"\";\n\n      model.on(\"change:value\", () => {\n        const newVal = model.get(\"value\") ?? \"\";\n\n        // Only update the visible input if the user hasn't typed since\n        // the last time we applied a model value.\n        const userHasTyped = input.value !== lastModelValue;\n        if (!userHasTyped) {\n            input.value = newVal;\n        }\n\n        lastModelValue = newVal;\n      });\n      \n      const sendMessage = () => {\n        const msg = (input.value || \"\").trim();\n        if (!msg) return;\n\n        model.set(\"submitted\", msg);\n        model.set(\"value\", msg);\n        // After submission we clear the input, but the model value becomes msg.\n        // Track it so subsequent model changes don't clobber a new draft.\n        lastModelValue = msg;\n        input.value = \"\";\n        model.save_changes();\n      };\n\n      btn.addEventListener(\"click\", sendMessage);\n\n      input.addEventListener(\"keydown\", (ev) => {\n        const sendOnEnter = !!model.get(\"send_on_enter\");\n        if (!sendOnEnter) return;\n        if (ev.key === \"Enter\" && !ev.shiftKey) {\n          ev.preventDefault();\n          sendMessage();\n        }\n      });\n    }\n    export default { render };\n    ",
       "_model_module": "anywidget",
       "_model_module_version": "~0.9.*",
       "_model_name": "AnyModel",
       "_view_module": "anywidget",
       "_view_module_version": "~0.9.*",
       "_view_name": "AnyView",
       "button_icon": "âž¤",
       "cell_id": "",
       "layout": "IPY_MODEL_9f38bf9f2cb547d299bb5d712288da31",
       "placeholder": "Type a message...",
       "position": "bottom",
       "send_on_enter": true,
       "submitted": "",
       "value": ""
      }
     },
     "9f38bf9f2cb547d299bb5d712288da31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bbceddcd455b41119043b55979a1d985": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8181adf609a04853a9a2a5fb5ba3588d",
       "style": "IPY_MODEL_ea31d70c6b2c49baacd18e6299dba488",
       "value": "\n            <div style=\"\n              color:#b5b5b5;\n              text-align:center;\n              padding:40px 0;\n              font-size:1.1em;\n              background:#fff;\n            \">ðŸ’¬ No messages yet. Start the conversation!</div>\n            "
      }
     },
     "e9320de6d5ed435e85967fea8aed6f8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "padding": "4px",
       "width": "100%"
      }
     },
     "ea31d70c6b2c49baacd18e6299dba488": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
